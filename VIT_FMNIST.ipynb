{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys"
      ],
      "metadata": {
        "id": "1DdqhuJvpIpv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing MNIST**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "a_T90gYgP6e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,Y_train),(X_test,Y_test)=tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "5iWVSVJ-pQ0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d6bd08-7201-4164-f90e-223fc6e1878f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255\n",
        "X_test=X_test/255"
      ],
      "metadata": {
        "id": "8ifQ4zOKpdBQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining VIT architecture**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nsde-Y9YQBVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self,d_model,num_heads,rate):\n",
        "    super(Attention,self).__init__()\n",
        "    self.d_model=d_model\n",
        "    self.num_heads=num_heads\n",
        "    self.Key=tf.keras.layers.Dense(d_model)\n",
        "    self.Query=tf.keras.layers.Dense(d_model)\n",
        "    self.Value=tf.keras.layers.Dense(d_model)\n",
        "    self.dropout=tf.keras.layers.Dropout(rate=rate)\n",
        "    self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def AttScore(self,K,Q,V,batch_size):\n",
        "    kq=tf.matmul(Q,K,transpose_b=True)\n",
        "    kq=kq/tf.sqrt(tf.cast(self.d_model,tf.float32))\n",
        "    soft=tf.nn.softmax(kq,axis=-1)\n",
        "    return tf.matmul(soft,V)\n",
        "                                # [ Batch_size , seq_len , d_model ] -> [ Batch_size , num_heads , seq_len , depth ]\n",
        "  def split_heads(self,inputs,batch_size):        # [ Batch_size , image_height , image_width ] -> [ Batch_size , number_of_patches , patch_height , patch_width ]\n",
        "    X=tf.reshape(inputs,(batch_size,-1,self.num_heads,self.d_model//self.num_heads))\n",
        "    return tf.transpose(X,perm=[0,2,1,3])\n",
        "\n",
        "  def call(self,inputs,training):\n",
        "    batch_size=tf.shape(inputs)[0]\n",
        "    K=self.Key(inputs)\n",
        "    Q=self.Query(inputs)\n",
        "    V=self.Value(inputs)\n",
        "    key=self.split_heads(K,batch_size)\n",
        "    query=self.split_heads(Q,batch_size)\n",
        "    value=self.split_heads(V,batch_size)\n",
        "    AttScore=self.AttScore(key,query,value,batch_size)\n",
        "    AttScore=tf.transpose(AttScore,perm=[0,2,1,3])\n",
        "    AttScore=tf.reshape(AttScore,(batch_size,-1,self.d_model))\n",
        "    AttScore=self.dropout(AttScore,training=training)\n",
        "    return self.norm(inputs+AttScore)"
      ],
      "metadata": {
        "id": "ohwWRUvKpnR-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointwiseFFN(tf.keras.layers.Layer):\n",
        "  def __init__(self,dff,d_model,rate):\n",
        "    super(PointwiseFFN,self).__init__()\n",
        "    self.d_model=d_model\n",
        "    self.dense1=tf.keras.layers.Dense(dff,activation='relu')\n",
        "    self.dense2=tf.keras.layers.Dense(d_model )\n",
        "    self.dropout=tf.keras.layers.Dropout(rate=rate)\n",
        "    self.norm=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def call(self,inputs,training):\n",
        "    X=self.dense1(inputs)\n",
        "    X=self.dense2(X)\n",
        "    X=self.dropout(X,training=training)\n",
        "    return self.norm(inputs+X)"
      ],
      "metadata": {
        "id": "2VMm7BLarnac"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VITLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,d_model,num_heads,dff,rate):\n",
        "    super(VITLayer,self).__init__()\n",
        "    self.mha=Attention(d_model,num_heads,rate)\n",
        "    self.FFN=PointwiseFFN(dff,d_model,rate)\n",
        "\n",
        "  def call(self,inputs,training):\n",
        "    X=self.mha(inputs,training=training)\n",
        "    X=self.FFN(X,training=training)\n",
        "    return X"
      ],
      "metadata": {
        "id": "hTjYDfc0sp-g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VIT(tf.keras.models.Model):\n",
        "  def __init__(self,d_model,num_heads,dff,num_layers,num_patches,rate):\n",
        "    super(VIT,self).__init__()\n",
        "    self.d_model=d_model\n",
        "    self.num_layers=num_layers\n",
        "    self.num_patches=num_patches\n",
        "    self.embedding=tf.keras.layers.Dense(d_model)\n",
        "    self.PosEn=self.PositionalEn(num_patches,d_model)\n",
        "    self.enc_layers=[VITLayer(d_model,num_heads,dff,rate) for _ in range(num_layers)]\n",
        "    self.global_pool = tf.keras.layers.GlobalAveragePooling1D()\n",
        "    self.dense1=tf.keras.layers.Dense(64,activation='relu')\n",
        "    self.dense2=tf.keras.layers.Dense(10,activation='softmax')\n",
        "\n",
        "  def PositionalEn(self,num_patches,d_model):\n",
        "    angles=self.GetAngle(np.arange(num_patches)[:,np.newaxis],np.arange(d_model)[np.newaxis,:],d_model)\n",
        "    angles[:,0::2]=np.sin(angles[:,0::2])\n",
        "    angles[:,1::2]=np.cos(angles[:,1::2])\n",
        "    pos_en=angles[np.newaxis,...]\n",
        "    return tf.cast(pos_en,dtype=tf.float32)\n",
        "\n",
        "  def GetAngle(self,pos,i,d_model):\n",
        "    angle_rates=1/np.power(10000,(2*(i//2))/np.float32(d_model))\n",
        "    return pos*angle_rates\n",
        "\n",
        "  def call(self,inputs,training=False):\n",
        "    num_patches=tf.shape(inputs)[1]\n",
        "    X=self.embedding(inputs)\n",
        "    X+=self.PosEn[:,:num_patches,:]\n",
        "    for i in range(self.num_layers):\n",
        "      X=self.enc_layers[i](X,training=training)\n",
        "    X=self.global_pool(X)\n",
        "    X=self.dense1(X)\n",
        "    return self.dense2(X)\n"
      ],
      "metadata": {
        "id": "CYgIxjdFs8ua"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model=150\n",
        "num_heads=5\n",
        "dff=256\n",
        "num_layers=2\n",
        "num_patches=4\n",
        "rate=0.0\n",
        "model=VIT(d_model,num_heads,dff,num_layers,num_patches,rate)"
      ],
      "metadata": {
        "id": "Yc3xrbaUWEMu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Patching Images**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mUX4qGpjQI7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_image(inputs,patch_size=[14,14]):        # [ batch_size , image_height , image_width ] -> [ batch_size , num_patches , flatten_patch ]\n",
        "  image_shape=inputs.shape\n",
        "  assert (image_shape[1]*image_shape[2])%(patch_size[0]*patch_size[1])==0,'image size is not divisible by patch size'\n",
        "  num_patches=(image_shape[1]*image_shape[2])//(patch_size[0]*patch_size[1])\n",
        "  return np.reshape(inputs,(image_shape[0],num_patches,(image_shape[1]*image_shape[2])//num_patches))"
      ],
      "metadata": {
        "id": "ij2jnnLyWvov"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_trainPatch=patch_image(X_train)\n",
        "X_testPatch=patch_image(X_test)"
      ],
      "metadata": {
        "id": "zAw0t-9dQWzD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataset = tf.data.Dataset.from_tensor_slices((X_trainPatch, Y_train))\n",
        "testDataset = tf.data.Dataset.from_tensor_slices((X_testPatch, Y_test))\n",
        "trainDataset = trainDataset.shuffle(buffer_size=1024).batch(64,drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)\n",
        "testDataset = testDataset.batch(64,drop_remainder=True).cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "nCvdWVXoYkRP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compile and train model**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "kYyW0Pu1QOAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "efW1fIEyUskz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainDataset,epochs=8,validation_data=testDataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKx6-DkgUgCf",
        "outputId": "5d4ee4f8-9f99-484e-9612-cf6dd9da5835"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8891 - loss: 0.2964 - val_accuracy: 0.8721 - val_loss: 0.3565\n",
            "Epoch 2/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8921 - loss: 0.2844 - val_accuracy: 0.8641 - val_loss: 0.3679\n",
            "Epoch 3/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2764 - val_accuracy: 0.8704 - val_loss: 0.3482\n",
            "Epoch 4/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8998 - loss: 0.2601 - val_accuracy: 0.8735 - val_loss: 0.3636\n",
            "Epoch 5/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2535 - val_accuracy: 0.8772 - val_loss: 0.3499\n",
            "Epoch 6/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.2454 - val_accuracy: 0.8778 - val_loss: 0.3421\n",
            "Epoch 7/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9076 - loss: 0.2399 - val_accuracy: 0.8780 - val_loss: 0.3548\n",
            "Epoch 8/8\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2322 - val_accuracy: 0.8757 - val_loss: 0.3423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2624d07d00>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}